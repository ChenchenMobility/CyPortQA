{"cells":[{"cell_type":"markdown","metadata":{"id":"mdQW9oR62Ffj"},"source":["### Setup GPT API"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8826,"status":"ok","timestamp":1753494243424,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"pY7Vm9vkWxla","outputId":"02050b53-758f-4dce-ad40-f50029984310"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"id\":\"d4dfce8d-e445-11a0-3973-34f767ee2d8a\",\"object\":\"chat.completion\",\"created\":1753494234,\"model\":\"grok-3\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"The question \\\"What is the meaning of life, the universe, and everything?\\\" is famously associated with Douglas Adams' science fiction series *The Hitchhiker's Guide to the Galaxy*. In the story, a supercomputer called Deep Thought is tasked with finding the answer to this ultimate question. After 7.5 million years of computation, Deep Thought reveals that the answer is **42**—but it also admits that the question itself is not fully understood, and a second computer (Earth) is needed to figure out the actual question.\\n\\nPhilosophically and culturally, this has become a humorous way to highlight the complexity and perhaps absurdity of seeking a single, definitive meaning to existence. Beyond the fictional reference, the \\\"meaning of life\\\" varies depending on individual perspectives, cultural beliefs, and philosophical or religious frameworks. Here are a few interpretations:\\n\\n1. **Philosophical Perspective**: Existentialist thinkers like Jean-Paul Sartre and Albert Camus suggest that life has no inherent meaning, and it is up to each individual to create their own purpose through choices and actions.\\n   \\n2. **Religious Perspective**: Many religions offer answers based on faith. For example, in Christianity, the meaning of life might be to love and serve God; in Buddhism, it might be to achieve enlightenment and escape the cycle of suffering.\\n\\n3. **Scientific Perspective**: From a biological standpoint, life could be seen as a self-replicating pattern of matter and energy, with no inherent \\\"meaning\\\" beyond survival and reproduction. Cosmologically, the universe's \\\"purpose\\\" remains unknown, as science focuses on how things work rather than why they exist.\\n\\n4. **Personal Perspective**: Ultimately, many people find meaning through relationships, creativity, personal growth, helping others, or pursuing happiness.\\n\\nSo, while \\\"42\\\" is the whimsical answer from fiction, the real answer depends on who you ask and how you choose to define it for yourself. What do you think—do you have a personal take on this question?\",\"refusal\":null},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":19,\"completion_tokens\":396,\"total_tokens\":415,\"prompt_tokens_details\":{\"text_tokens\":19,\"audio_tokens\":0,\"image_tokens\":0,\"cached_tokens\":2},\"completion_tokens_details\":{\"reasoning_tokens\":0,\"audio_tokens\":0,\"accepted_prediction_tokens\":0,\"rejected_prediction_tokens\":0},\"num_sources_used\":0},\"system_fingerprint\":\"fp_0d42a4eb3d\"}"]}],"source":["import os\n","import json\n","\n","XAI_API_KEY = \"\"\n","\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {XAI_API_KEY}\"\n","}\n","\n","data = {\n","    \"messages\": [\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"What is the meaning of life, the universe, and everything?\"\n","        }\n","    ],\n","    \"model\": \"grok-3-latest\",\n","    \"stream\": False,\n","    \"temperature\": 0.7\n","}\n","\n","with open(\"payload.json\", \"w\") as f:\n","    json.dump(data, f)\n","\n","!curl https://api.x.ai/v1/chat/completions \\\n","  -H \"Content-Type: application/json\" \\\n","  -H \"Authorization: Bearer {XAI_API_KEY}\" \\\n","  -d @payload.json\n","\n","LLMName = 'grok-4-0709'"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"executionInfo":{"elapsed":30196,"status":"ok","timestamp":1753494273626,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"D7QL7UqF18Qk"},"outputs":[],"source":["%%capture\n","# ✅ STEP 1: Load packages and ChatGPT API\n","# Install all necessary pachages\n","!apt-get install -y poppler-utils\n","!apt-get install -y tesseract-ocr\n","! pip install -U langchain openai langchain-chroma langchain-experimental # (newest versions required for multi-modal)\n","! pip install \"unstructured[all-docs]\" pillow pydantic lxml pillow matplotlib chromadb tiktoken\n","!pip install -U langchain-openai\n","!pip install xai-sdk"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3447,"status":"ok","timestamp":1753494277081,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"GTFFP1MY18TI","outputId":"5383a3d8-f23e-4034-c6a3-b576b8c919e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import base64\n","from PIL import Image\n","from io import BytesIO\n","from langchain_core.documents import Document\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain.retrievers.multi_vector import MultiVectorRetriever\n","from langchain.storage import InMemoryStore\n","from langchain_chroma import Chroma\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","import os\n","import time\n","import pandas as pd\n","import base64\n","from joblib import Parallel, delayed\n","from pathlib import Path\n","import random\n","\n","from google.colab import drive\n","import pandas as pd\n","from pathlib import Path\n","from IPython.display import display\n","from PIL import Image\n","\n","drive.mount('/content/drive')\n","\n","# Base folders\n","base_folder = Path(\"/content/drive/MyDrive/LLMs/MLLM_CW/0723_Shuffle\")\n","\n","# Put your API key here\n","os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with your key"]},{"cell_type":"markdown","metadata":{"id":"GJ21f2xE2SEm"},"source":["### Data Loading and partition"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2448,"status":"ok","timestamp":1753494279539,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"TbqnAp-dWSSr"},"outputs":[],"source":["from pathlib import Path\n","import json\n","\n","# Assuming you have already mounted the drive and defined:\n","# base_folder = Path(\"/content/drive/MyDrive/LLMs/MLLM_CW/0723_Shuffle\")\n","\n","json_path = base_folder / \"Final_QA_JSON_filtered_0723.json\"\n","\n","# Open the file correctly\n","with open(json_path, \"r\", encoding=\"utf-8\") as f:\n","    QASet = json.load(f)\n","\n","EventNames = list(QASet.keys())"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1753494279541,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"GU-GrkUqWSX8"},"outputs":[],"source":["import os\n","import base64\n","\n","def write_message(Q_current, InputFileFolder):\n","    Q_modalities = Q_current['modalities']\n","    storm, year, leadtime = Q_current['context'][-3:]\n","\n","    messages = [{\"role\": \"system\", \"content\": Q_current['prompt']}]\n","\n","    for modality in Q_modalities:\n","        filename = f\"{storm}_{year}_{leadtime}h\"\n","        folder_path = os.path.join(InputFileFolder, modality)\n","\n","        if modality in ['Graphic_Uncertainty_cone', 'Graphic_Wind']:\n","            image_path = os.path.join(folder_path, f\"{filename}.png\")\n","            with open(image_path, \"rb\") as img_file:\n","                image_b64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n","                messages.append({\n","                    \"role\": \"user\",\n","                    \"content\": [{\n","                        \"type\": \"image_url\",\n","                        \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}\n","                    }]\n","                })\n","\n","        elif modality in ['text_advisory', 'Table_wind']:\n","            text_path = os.path.join(folder_path, f\"{filename}.txt\")\n","            with open(text_path, \"r\", encoding=\"utf-8\") as text_file:\n","                advisory_text = text_file.read()\n","                messages.append({\n","                    \"role\": \"user\",\n","                    \"content\": advisory_text\n","                })\n","        else:\n","            raise ValueError('Unknown Modality Input!')\n","\n","    # Append question\n","    messages.append({\n","        \"role\": \"user\",\n","        \"content\": Q_current['question']\n","    })\n","\n","    true_answer = Q_current['answer']\n","    return messages, true_answer"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1753494279543,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"PdfyFZCrWSaX"},"outputs":[],"source":["def run_LLM(EventIdx, InputFileFolder):\n","    EventName_thisevent = EventNames[EventIdx]\n","    print(f\"EventIdx = {EventIdx}, EventName = {EventName_thisevent}, LLM = {LLMName}\")\n","    QASet_thisevent = QASet[EventNames[EventIdx]]['qa']\n","    QASet_thisevent_indexed = list(enumerate(QASet_thisevent))\n","    random.shuffle(QASet_thisevent_indexed)\n","\n","    results_dict = {}\n","\n","    for idx_q, q in QASet_thisevent_indexed:\n","        t1 = time.time()\n","        message_thisq, true_answer = write_message(q, InputFileFolder)\n","        response = call_xai_llm(message_thisq)\n","        t2 = time.time()\n","\n","        results_dict[idx_q] = {\n","            \"response\": response,\n","            \"ground_truth\": true_answer\n","        }\n","\n","        print(f\"Evtid = {EventIdx}, Q_idx = {idx_q}, elapsed time = {t2 - t1:.4f}\")\n","\n","    results_thisevent = [results_dict[idx] for idx in sorted(results_dict)]\n","    df = pd.DataFrame(results_thisevent)\n","    final_output_path = Path(base_folder) / \"MultiModalOutputs\" / safe_LLMName / f\"EvtID{EventIdx}_{EventName_thisevent}.csv\"\n","    df.to_csv(final_output_path, index=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":156,"status":"ok","timestamp":1753494279699,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"fQY9Vu9mXKnR"},"outputs":[],"source":["\n","from xai_sdk import Client\n","from xai_sdk.chat import user, system\n","\n","client = Client(api_key=\"xai-EVBdlIh1Mg69TATXVOLcCoxtr4JhEbZED6nU440B82wouKi7sEQO5kvijM9AFVsJTXk08GvcsD8rFeaP\")\n","XAI_API_KEY = \"xai-EVBdlIh1Mg69TATXVOLcCoxtr4JhEbZED6nU440B82wouKi7sEQO5kvijM9AFVsJTXk08GvcsD8rFeaP\"\n","\n","# Choose model\n","LLMName = 'grok-4-0709'  # You can change to 'gpt-4', 'gpt-3.5-turbo', etc.\n","safe_LLMName = LLMName.replace(':', '_')\n","InputFileFolder = base_folder /'MultiModalInputs'\n","\n","# Output path\n","path = Path(base_folder) / \"MultiModalOutputs\" / safe_LLMName\n","path.mkdir(parents=True, exist_ok=True)\n","\n","# Wrapper function to mimic `llm.invoke()`\n","def call_xai_llm(messages):\n","    chat = client.chat.create(model=\"grok-4-0709\", temperature=0)\n","\n","    for msg in messages:\n","        role = msg[\"role\"]\n","        content = msg[\"content\"]\n","\n","        if isinstance(content, list):\n","            content = \" \".join(str(c) for c in content)  # flatten any list just in case\n","\n","        if role == \"user\":\n","            chat.append(user(content))\n","        elif role == \"system\":\n","            chat.append(system(content))\n","        else:\n","            raise ValueError(f\"Unsupported role: {role}\")\n","\n","    response = chat.sample()\n","    return response.content.strip()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":113759,"status":"error","timestamp":1753494393465,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"YHCaE61sWScz","outputId":"05b55e68-5aa4-4571-8ec1-1031f988ac26"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running LLM for EventIdx = 0\n","EventIdx = 0, EventName = ANA_2015_Port_of_Savannah,_GA, LLM = grok-4-0709\n","Evtid = 0, Q_idx = 4, elapsed time = 29.7537\n","Evtid = 0, Q_idx = 121, elapsed time = 68.2214\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-8-560245945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# from 1 to 100 inclusive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nRunning LLM for EventIdx = {event_index}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun_LLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFileFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-6-805118332.py\u001b[0m in \u001b[0;36mrun_LLM\u001b[0;34m(EventIdx, InputFileFolder)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmessage_thisq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFileFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_xai_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_thisq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-7-2616721899.py\u001b[0m in \u001b[0;36mcall_xai_llm\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unsupported role: {role}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xai_sdk/sync/chat.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;34m\"I'm doing great, thanks for asking!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetCompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompression\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_FailureOutcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         call = self._interceptor.intercept_unary_unary(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xai_sdk/client.py\u001b[0m in \u001b[0;36mintercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mintercept_unary_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Intercepts a unary-unary RPC call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intercept_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mintercept_unary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xai_sdk/client.py\u001b[0m in \u001b[0;36m_intercept_call\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_intercept_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mclient_call_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mintercept_unary_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_call_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    313\u001b[0m             ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_call_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             )\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0m_handle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n","\u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001b[0m in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for event_index in range(0, 101):  # from 1 to 100 inclusive\n","    print(f\"\\nRunning LLM for EventIdx = {event_index}\")\n","    run_LLM(event_index, InputFileFolder)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1753494393477,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"4cPJlYpAWSfR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1753494393488,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"qfKNcg6-WSh4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":0,"status":"aborted","timestamp":1753494393489,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"_0s8tcyIWSkj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1753494393491,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"iv5-vgeaWSm7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1753494393492,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"p-KI1GFQWSpx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158931,"status":"aborted","timestamp":1753494393493,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"HeoM5Yz818Vm"},"outputs":[],"source":["from langchain_core.messages import HumanMessage\n","\n","# ✅ STEP 2: Image Encoding and Summary Helper\n","# Load and encode image\n","def encode_image(image_path):\n","    with Image.open(image_path).convert(\"RGB\") as img:\n","        buffered = BytesIO()\n","        img.save(buffered, format=\"JPEG\")\n","        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n","\n","# Summarize cyclone scenario with structured schema\n","def summarize_scenario(cone_img_path, wind_img_path, advisory_text, wind_text,\n","                             port_name, cyclone_name):\n","    # Encode both images\n","    base64_cone = encode_image(cone_img_path)\n","    base64_wind = encode_image(wind_img_path)\n","\n","    # Enhanced prompt\n","    prompt = prompt = f\"\"\"\n","Act as expert in port operation specialist and tropical cyclone analyst. Based on the provided graphics and texts, extract information into the following structured JSON schema. The current senario information are given:\n","\n","**Port Name**: {port_name}\n","**Cyclone Name**: {cyclone_name}\n","\n","You must extract relevant details and populate the following **structured JSON schema**. This schema supports operational decision-making and resilience analysis for ports. Carefully read the **inline annotations** next to each field — they describe exactly what must be extracted. Use all available sources: graphics for movement, proximity, and timing; text for classification, warnings, and hazard probabilities.\n","\n","JSON Format:\n","{{\n","  \"cyclone\": {{\n","    \"name\": \"{cyclone_name}\",                   // Cyclone identifier\n","    \"category\": \"\",                             // Current SSHS classification (e.g., \"Category 1\")\n","    \"current_location\": \"\",                     // Verbal location (e.g., \"about 200 miles SE of Galveston\")\n","    \"coordinates\": \"\",                          // Lat/Lon format (e.g., \"22.3N, 86.6W\")\n","    \"motion\": {{\n","      \"direction\": \"\",                          // e.g., \"WNW\"\n","      \"speed\": \"\"                               // e.g., \"14 mph\"\n","    }},\n","    \"trajectory\": \"\",                           // Describe the cyclone's predicted path direction and target area (e.g., \"tracking northwest toward Gulf Coast\")\n","    \"expected_landfall_location\": \"\",           // Closest landfall or coastal encounter\n","    \"expected_landfall_date\": \"\",               // e.g., \"2022-06-05\"\n","    \"hours_to_landfall\": \"\",                    // e.g., \"48\"\n","    \"hours_to_offshore\": \"\",                    // Estimated number of hours until the storm moves offshore from {port_name}'s coast (e.g., \"24\")\n","    \"hours_of_strike\": \"\",                      // Estimated number of hours from the storm’s initial strike to its departure at {port_name} (e.g., \"12\")\n","  }},\n","  \"port\": {{\n","    \"name\": \"{port_name}\"                       // Full port name\n","  }},\n","  \"weather_observation\": {{\n","    \"within_uncertainty_cone\": \"\",              // If the port located within the uncertainty cone of the tropical cyclone, e.g. \"Yes\" or \"No\"\n","    \"forecast_window\":\"\",                       // How many days are there in the forecast window shown from the uncertainty cone track, e.g. 5\n","    \"under_watch\": \"\",                          // The watch information at the port, e.g., \"Tropical Storm Watch\",\"Hurricane Watch\", \"None\"\n","    \"under_warning\": \"\",                        // The warning information at the port, e.g., \"Tropical Storm Warning\",\"Hurricane Warning\", \"None\"\n","    \"watch_coast\": \"\",                          // Describe geographic extent of watch area\n","    \"warning_coast\": \"\",                        // Describe geographic extent of warning area\n","    \"impacted_coast\": \"\",                       // Describe geographic extent of coast area impacted by the tropical cyclone\n","    \"expected_closest_date_to_port\": \"\",        // Closest approach date\n","    \"expected_leaving_port_date\": \"\",           // Estimated time cyclone moves away from port influence\n","    \"closest_wind_data_location\":\"\",            // The closest wind location to {port_name} in wind probability table, e.g. \"BOSTON MA\"\n","    \"culmulative_wind_34kt\":\"\",                 // cumulative probability of 34kt wind arrival at {port_name} in future 5 days\n","    \"culmulative_wind_50kt\":\"\",                 // cumulative probability of 50kt wind arrival at {port_name} in future 5 days\n","    \"34kt_max\":\"\",                              // probability value when 34kt wind probability peaks at {port_name} in future 5 days\n","    \"time_to_34kt_max\":\"\",                      // number of hours to 34kt wind probability peaks at {port_name} in future 5 days\n","    \"time_to_34kt_non_zero\":\"\",                 // number of hours to 34kt wind probability become non-zero at {port_name} in future 5 days\n","    \"time_to_50kt_max\":\"\",                      // number of hours to 34kt wind probability peaks at {port_name} in future 5 days\n","    \"gale_probability\": {{\n","      \"in 12h\": \"\",                             // Estimate the gale force probability at the port from the wind forecast table in future 12, 24, 48, 72 and 96 hours e.g., \"12%\"\n","      \"in 24h\": \"\",\n","      \"in 48h\": \"\",\n","      \"in 72h\": \"\",\n","      \"in 96h\": \"\"\n","    }},\n","    \"first_hazard\":\"\",                          // Select the earliest possible hazard happen at port, from \"TC’s landfall\",\"Arrival of tropical storm-force winds\", \"Start of heavy rainfall\" or \"Start of storm surge\"\n","    \"rain_fall_above_4_inch\":\"\",                // Estimate if rainfall at {port_name} could reach 4 inch in the event\n","    \"storm_surge_above_3_feet\":\"\",              // Estimate if surge height at {port_name} could reach 3 feet in the event\n","    \"wind\":\"\",                                  // Describe possible strong wind that could at {port_name}'s side, if no information is avaliable, output \"None\"\n","    \"storm_surge\":\"\",                           // Describe possible storm surge at {port_name}'s side, if no information is avaliable, output \"None\"\n","    \"rainfall\":\"\",                              // Describe possible heavy rainfall at {port_name}'s side, if no information is avaliable, output \"None\"\n","    \"other_hazards\": \"\"                         // Describe possible other hazards at {port_name}'s side that will impact operation\n","  }}\n","}}\n","\n","Evaluate on how the {port_name} is impacted by {cyclone_name}, be specific and rely on graphics for movement direction, cone shape, and timing. Use the advisory and text of wind probability table for wind speed, warnings, probability values, and hazard descriptions.\n","\"\"\"\n","\n","    # LLM call\n","    chat = ChatOpenAI(model=\"o3\",max_tokens=4096,model_kwargs={\"response_format\":{\"type\":\"json_object\"}})\n","    msg = chat.invoke([\n","        HumanMessage(\n","            content=[\n","                {\"type\": \"text\", \"text\": prompt},\n","                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_cone}\"}},\n","                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_wind}\"}},\n","                {\"type\": \"text\", \"text\": f\"Advisory Text:\\n{advisory_text}\"},\n","                {\"type\": \"text\", \"text\": f\"Wind Text:\\n{wind_text}\"}\n","            ]\n","        )\n","    ])\n","    return msg.content"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158930,"status":"aborted","timestamp":1753494393494,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"WJe8HMw918c9"},"outputs":[],"source":["# 🧪 Test Code: Hurricane Florance on Port of Charleston\n","from google.colab import drive\n","import pandas as pd\n","from pathlib import Path\n","from IPython.display import display\n","from PIL import Image\n","\n","drive.mount('/content/drive')\n","\n","# Base folders\n","base_folder = Path(\"/content/drive/MyDrive/LLMs/QA_Generation_GPT4o\")\n","metadata_file = base_folder / \"senarios_filtered.csv\"\n","\n","# Read scenario metadata\n","senario_metadata = pd.read_csv(metadata_file)\n","\n","# Define subfolders\n","cone_graphic_dir = base_folder / \"Cyclone Graphics Archive Uncertainty Cone\"\n","wind_graphic_dir = base_folder / \"Cyclone Graphics Archive Wind\"\n","advisory_text_dir = base_folder / \"Cyclone Text Archive Advisory\"\n","wind_text_dir = base_folder / \"Cyclone Text Archive Wind\"\n","\n","# Iterate through scenarios\n","for idx, row in senario_metadata.iloc[:1].iterrows():\n","    name = row['tc_name']\n","    year = int(row['year'])\n","    hour = int(row['hour'])\n","\n","    # Construct paths\n","    # Build base path without extension\n","    cone_image = cone_graphic_dir / f\"{name}_{year}_{hour}h\"\n","    matches_cone_image = list(cone_image.parent.glob(cone_image.name + \".*\"))\n","    wind_image = wind_graphic_dir / f\"{name}_{year}_{hour}h\"\n","    matches_wind_image = list(wind_image.parent.glob(wind_image.name + \".*\"))\n","    advisory_text_file = advisory_text_dir / f\"{name}_{year}_{hour}h.txt\"\n","    wind_text_file = wind_text_dir / f\"{name}_{year}_{hour}h.txt\"\n","\n","    # Print extracted paths and content\n","    print(f\"\\n📍 Scenario {idx + 1}: {row['port_name']} - {name} (Hour {hour} before landfall)\")\n","\n","    # Print and display cone image\n","    print(f\"🌀 Cone Image Path: {cone_image}\")\n","    if matches_cone_image:\n","        img = Image.open(matches_cone_image[0])\n","        resized_img = img.resize((400, int(img.height * 400 / img.width)))  # resize width to 400 px, keep aspect ratio\n","        display(resized_img)\n","    else:\n","        print(\"⚠️ Cone image not found.\")\n","\n","    # Print and display wind image\n","    print(f\"💨 Wind Image Path: {wind_image}\")\n","    if matches_wind_image:\n","        img = Image.open(matches_wind_image[0])\n","        resized_img = img.resize((400, int(img.height * 400 / img.width)))  # resize width to 400 px, keep aspect ratio\n","        display(resized_img)\n","    else:\n","        print(\"⚠️ Wind image not found.\")\n","\n","    # Read and print advisory text\n","    if advisory_text_file.exists():\n","        with open(advisory_text_file, 'r') as f:\n","            advisory_text = f.read()\n","        print(f\"📄 Advisory Text:\\n{advisory_text[:500]}...\")  # Preview first 500 chars\n","    else:\n","        print(\"⚠️ Advisory text file not found.\")\n","\n","    # Read and print wind text\n","    if wind_text_file.exists():\n","        with open(wind_text_file, 'r') as f:\n","            wind_text = f.read()\n","        print(f\"🌬️ Wind Text:\\n{wind_text[:500]}...\")  # Preview\n","    else:\n","        print(\"⚠️ Wind text file not found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158928,"status":"aborted","timestamp":1753494393495,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"dz5hWwVIsIqb"},"outputs":[],"source":["senario_metadata"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158926,"status":"aborted","timestamp":1753494393495,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"pndpmyyzS6bV"},"outputs":[],"source":["import json\n","from pathlib import Path\n","\n","summary_JSON = Path(\"summary_JSON\")  # Ensure this is defined properly\n","summary_JSON.mkdir(parents=True, exist_ok=True)  # Create folder if not exists\n","\n","# Select for experiment\n","subset_df = pd.concat([\n","    senario_metadata.iloc[2570:]\n","])\n","\n","excluded_pairs = [\n","    ('ELSA', 2021),\n","    ('ETA', 2020),\n","    ('FRED', 2021),\n","    ('IRMA', 2017),\n","    ('ISAIAS', 2020),\n","    ('LAURA', 2020),\n","    ('MATTHEW', 2016)\n","]\n","subset_df = subset_df[~subset_df[['tc_name', 'year']].apply(tuple, axis=1).isin(excluded_pairs)]\n","\n","# Iterate through scenarios\n","for idx, row in subset_df.iterrows():\n","    name = row['tc_name']\n","    year = int(row['year'])\n","    hour = int(row['hour'])\n","\n","    # Construct paths\n","    # Build base path without extension\n","    cone_image = cone_graphic_dir / f\"{name}_{year}_{hour}h\"\n","    matches_cone_image = list(cone_image.parent.glob(cone_image.name + \".*\"))\n","    wind_image = wind_graphic_dir / f\"{name}_{year}_{hour}h\"\n","    matches_wind_image = list(wind_image.parent.glob(wind_image.name + \".*\"))\n","    advisory_text_file = advisory_text_dir / f\"{name}_{year}_{hour}h.txt\"\n","    wind_text_file = wind_text_dir / f\"{name}_{year}_{hour}h.txt\"\n","\n","    # Print extracted paths and content\n","    print(f\"\\n📍 Scenario {idx + 1}: {row['port_name']} - {name} (Hour {hour} before landfall)\")\n","\n","    # Print and display cone image\n","    if matches_cone_image:\n","        img = Image.open(matches_cone_image[0])\n","        resized_img = img.resize((400, int(img.height * 400 / img.width)))  # resize width to 400 px, keep aspect ratio\n","    else:\n","        print(\"⚠️ Cone image not found.\")\n","\n","    # Print and display wind image\n","    if matches_wind_image:\n","        img = Image.open(matches_wind_image[0])\n","        resized_img = img.resize((400, int(img.height * 400 / img.width)))  # resize width to 400 px, keep aspect ratio\n","    else:\n","        print(\"⚠️ Wind image not found.\")\n","\n","    # Read and print advisory text\n","    if advisory_text_file.exists():\n","        with open(advisory_text_file, 'r') as f:\n","            advisory_text = f.read()\n","    else:\n","        print(\"⚠️ Advisory text file not found.\")\n","\n","    # Read and print wind text\n","    if wind_text_file.exists():\n","        with open(wind_text_file, 'r') as f:\n","            wind_text = f.read()\n","    else:\n","        print(\"⚠️ Wind text file not found.\")\n","\n","\n","    if all([\n","        advisory_text_file.exists(),\n","        wind_text_file.exists(),\n","        matches_cone_image,\n","        matches_wind_image\n","    ]):\n","        cone_img_path = matches_cone_image[0]\n","        wind_img_path = matches_wind_image[0]\n","\n","        with open(advisory_text_file, 'r') as f1, open(wind_text_file, 'r') as f2:\n","            advisory_text = f1.read()\n","            wind_text = f2.read()\n","\n","        try:\n","            summary = summarize_scenario(\n","                cone_img_path=cone_img_path,\n","                wind_img_path=wind_img_path,\n","                advisory_text=advisory_text,\n","                wind_text=wind_text,\n","                port_name=row['port_name'],\n","                cyclone_name=row['tc_name']\n","            )\n","\n","            print(\"🧠 Structured Summary:\\n\", summary)\n","\n","            # Create safe filenames\n","            tc_name_safe = str(row['tc_name']).replace(\" \", \"_\")\n","            port_name_safe = str(row['port_name']).replace(\" \", \"_\")\n","            # Define your base folder\n","            base_folder = Path(\"/content/drive/MyDrive/LLMs/QA_Generation_GPT4o\")\n","            summary_JSON = base_folder / \"summary_JSON\"\n","\n","            output_path = summary_JSON / f\"{tc_name_safe}_{year}_{port_name_safe}_{hour}_summary.json\"\n","\n","            # Save summary\n","            with open(output_path, 'w') as f:\n","                if isinstance(summary, dict):\n","                    json.dump(summary, f, indent=2)\n","                else:\n","                    f.write(summary)\n","\n","            print(f\"✅ JSON saved to: {output_path}\")\n","\n","        except Exception as e:\n","            print(f\"❌ Skipped due to error: {type(e).__name__} - {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158927,"status":"aborted","timestamp":1753494393496,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"49fYLS4ZjOin"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158928,"status":"aborted","timestamp":1753494393497,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"UQxtkaPelxK4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158928,"status":"aborted","timestamp":1753494393498,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"l6VirZXVlxNb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158928,"status":"aborted","timestamp":1753494393498,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"loK3oAjSlxP1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158929,"status":"aborted","timestamp":1753494393499,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"hZFEBshVjOlg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158930,"status":"aborted","timestamp":1753494393500,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"V81r7VzVjOoq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158930,"status":"aborted","timestamp":1753494393500,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"sIHXmR26a43e"},"outputs":[],"source":["# Impact prediction\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158951,"status":"aborted","timestamp":1753494393522,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"bzkfxm8-S6eG"},"outputs":[],"source":["# Senario Encoding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158952,"status":"aborted","timestamp":1753494393523,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"UTX6EA3tS7TX"},"outputs":[],"source":["# Vessel routing\n"]},{"cell_type":"markdown","metadata":{"id":"q1O__4mkS8hD"},"source":["### Iterative code"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158950,"status":"aborted","timestamp":1753494393523,"user":{"displayName":"Chenchen Kuai","userId":"16426867159365045469"},"user_tz":300},"id":"sNaKBXru18fi"},"outputs":[],"source":["# ✅ STEP 3: Senario multimodal data organization\n","from google.colab import drive\n","import pandas as pd\n","\n","drive.mount('/content/drive')\n","\n","# Base folders\n","base_folder = Path(\"/content/drive/MyDrive/LLMs/QA_Generation_GPT4o\")\n","metadata_file = base_folder / \"Cyclone Senarios.csv\"\n","\n","# Read scenario metadata\n","senario_metadata = pd.read_csv(metadata_file)\n","\n","# Define subfolders\n","cone_graphic_dir = base_folder / \"Cyclone Graphics Archive Uncertainty Cone\"\n","wind_graphic_dir = base_folder / \"Cyclone Graphics Archive Wind\"\n","advisory_text_dir = base_folder / \"Cyclone Text Archive Advisory\"\n","wind_text_dir = base_folder / \"Cyclone Text Archive Wind\"\n","\n","# Iterate through scenarios\n","for idx, row in senario_metadata.iterrows():\n","    name = row['NAME']\n","    day = int(row['Day_before_Landfall'])\n","\n","    # Construct paths\n","    cone_image = cone_graphic_dir / f\"{name}_Day_{day}.png\"\n","    wind_image = wind_graphic_dir / f\"{name}_Day_{day}.png\"\n","    advisory_text_file = advisory_text_dir / f\"{name}_Day_{day}.txt\"\n","    wind_text_file = wind_text_dir / f\"{name}_Day_{day}.txt\"  # typo fixed: .png ➝ .txt\n","\n","    # Print extracted paths and content\n","    print(f\"\\n📍 Scenario {idx + 1}: {row['PORT']} - {name} (Day {day} before landfall)\")\n","\n","    print(f\"🌀 Cone Image Path: {cone_image}\")\n","    print(f\"💨 Wind Image Path: {wind_image}\")\n","\n","    # Read and print advisory text\n","    if advisory_text_file.exists():\n","        with open(advisory_text_file, 'r') as f:\n","            advisory_text = f.read()\n","        print(f\"📄 Advisory Text:\\n{advisory_text[:500]}...\")  # Preview first 500 chars\n","    else:\n","        print(\"⚠️ Advisory text file not found.\")\n","\n","    # Read and print wind text\n","    if wind_text_file.exists():\n","        with open(wind_text_file, 'r') as f:\n","            wind_text = f.read()\n","        print(f\"🌬️ Wind Text:\\n{wind_text[:500]}...\")  # Preview\n","    else:\n","        print(\"⚠️ Wind text file not found.\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNq9oAau8ajTLfnx5AznpiR","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
