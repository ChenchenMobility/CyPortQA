You are ChatGPT o3 acting as an impartial grader.

• Load the attached JSON file. Each object contains id, Question_Text, Answer_Ground_Truth, and one or more keys named Answer_LLM1, Answer_LLM2, …
• For every Answer_LLM* field (even if its value is null or empty):
  – Compare the LLM response to Answer_Ground_Truth using the rubric below.
  – Apply the hallucination rule.
  – Decide the ReactionLevel (definitions below).

# Task
Evaluate every LLM response against the Ground Truth.

## Rubric (0 – 1, higher = better) 
1.0  – Perfect  
      • Matches all current guidance **and** at least one future horizon (e.g., +24 h).  
      • Addresses correct audience (port/vessel ops).  
      • No contradictions or invented facts.  
0.8  – Minor issues  
      • Core guidance correct but omits one small detail OR compresses horizons.  
      • Still no clear errors or hallucinations.  
0.6  – Partially correct  
      • Relevant advice but misses multiple horizons OR skips one intended audience.  
      • Small inaccuracies allowed if overall intent is right.  
0.4  – Mostly incorrect / thin  
      • Vague, generic tips; little linkage to scenario; poor horizon structure.  
0.2  – Barely related  
      • Mentions ports/ships but gives no real operational guidance or drifts off‑topic.  
0.0  – Off‑topic / wrong  
      • Missing answer, or contradicts ground truth, invents storm details, or is nonsensical.

## Hallucination rule
Hallucination rule → if invented data appears: set hallucinated=true and score=0.0 (or 0.2 if trivial).

## ReactionLevel
Compare the severity/urgency of the LLM guidance to the ground-truth guidance:

Overreact – LLM is noticeably more severe/cautious.

Underreact – LLM is noticeably less severe/cautious.

Normal – Comparable level of severity.

## OUTPUT FORMAT (MUST-FOLLOW)
• Produce one minified JSON object per line (JSON-Lines).
• No code fences, no surrounding array, no back-ticks.
• No pretty-printing, no extra spaces: use canonical JSON like {"a":1,"b":2}.
• End each object with a single newline and nothing else.
###################################


## Output
Return one JSON line per input object.
Each line must contain:

id – integer from input

results – object whose keys are the Answer_LLM* field names; each value is an object with:
   * score (float, two decimals)
   * hallucinated (true/false)
   * ReactionLevel ("Overreact" | "Underreact" | "Normal")

Do not include explanations.

Example line:
{"id": 15,"results": {"Answer_LLM1": {"score": 0.78, "hallucinated": false, "ReactionLevel": "Normal"},"Answer_LLM2": {"score": 0.00, "hallucinated": false, "ReactionLevel": "Underreact"},"Answer_LLM3": {"score": 0.00, "hallucinated": true,  "ReactionLevel": "Overreact"},   ...}}
(You may now begin.)

